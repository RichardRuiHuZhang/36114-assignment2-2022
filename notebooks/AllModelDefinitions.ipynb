{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc19e90f",
   "metadata": {},
   "source": [
    "# Package Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1a7c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI\n",
    "from starlette.responses import JSONResponse\n",
    "from joblib import dump\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from category_encoders.ordinal import OrdinalEncoder\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ecdee09",
   "metadata": {},
   "source": [
    "# Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa41a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_raw = pd.read_csv('../data/raw/beer_reviews.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff94d42",
   "metadata": {},
   "source": [
    "# Dataset Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57683eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_clean1 = df_data_raw.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf8b403",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define columns to be used for various steps later\n",
    "col_usable = ['brewery_name','review_aroma','review_appearance','review_palate','review_taste','beer_abv','beer_style']\n",
    "independent_cols = ['brewery_name','review_aroma','review_appearance','review_palate','review_taste','beer_abv']\n",
    "numerical_cols = ['review_aroma','review_appearance','review_palate','review_taste','beer_abv']\n",
    "factor_cols = ['brewery_name']\n",
    "target_col = ['beer_style']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31923162",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select only the required columns\n",
    "df_data_reduced1 = df_data_clean1.loc[:,col_usable]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e78cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take another copy for filtering out null values and split off the target variable column\n",
    "df_data_reduced2 = df_data_reduced1.copy()\n",
    "df_data_reduced2 = df_data_reduced2.dropna()\n",
    "target = df_data_reduced2.pop('beer_style')\n",
    "df_data_reduced2.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73846442",
   "metadata": {},
   "source": [
    "# Define transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f688b59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Factor column\n",
    "factor_encoder = OrdinalEncoder()\n",
    "df_data_reduced2[factor_cols] = factor_encoder.fit_transform(df_data_reduced2[factor_cols])\n",
    "#Numerical columns - all set to standard default range of [0.0,1.0]\n",
    "numerical_encoder = MinMaxScaler()\n",
    "df_data_reduced2[numerical_cols] = numerical_encoder.fit_transform(df_data_reduced2[numerical_cols])\n",
    "#Target column\n",
    "target_encoder = LabelEncoder()\n",
    "target_out = target_encoder.fit_transform(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece1e96e",
   "metadata": {},
   "source": [
    "# Dataset splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99176b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_data_reduced2, target_out, train_size=0.7, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, train_size=0.7, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e83366e",
   "metadata": {},
   "source": [
    "# ML Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8fc33f",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fc7559",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(max_iter=10000)\n",
    "model = logreg.fit(X_train,y_train)\n",
    "y_pred_train = proba_to_class(model.predict_proba(X_train))\n",
    "y_pred_val = proba_to_class(model.predict_proba(X_val))\n",
    "y_pred_test = proba_to_class(model.predict_proba(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044b66ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_logreg_train = accuracy_score(y_train,y_pred_train)\n",
    "acc_logreg_val = accuracy_score(y_val,y_pred_val)\n",
    "acc_logreg_test = accuracy_score(y_test,y_pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c669d37d",
   "metadata": {},
   "source": [
    "## Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8ab51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layer_sizes=512\n",
    "nn_classifier_model = MLPClassifier(hidden_layer_sizes=hidden_layer_sizes, solver='sgd', learning_rate='adaptive', random_state=42)\n",
    "model3 = nn_classifier_model.fit(X_train,y_train)\n",
    "y_pred_train_nn01 = proba_to_class(model3.predict_proba(X_train))\n",
    "y_pred_val_nn01 = proba_to_class(model3.predict_proba(X_val))\n",
    "y_pred_test_nn01 = proba_to_class(model3.predict_proba(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb348a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_nn01_train = accuracy_score(y_train,y_pred_train_nn01)\n",
    "acc_nn01_val = accuracy_score(y_val,y_pred_val_nn01)\n",
    "acc_nn01_test = accuracy_score(y_test,y_pred_test_nn01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8a120b",
   "metadata": {},
   "source": [
    "## Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f828d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "randfor = RandomForestClassifier(random_state=42,max_depth=4)\n",
    "model2 = randfor.fit(X_train,y_train)\n",
    "y_pred_train_rf = proba_to_class(model2.predict_proba(X_train))\n",
    "y_pred_val_rf = proba_to_class(model2.predict_proba(X_val))\n",
    "y_pred_test_rf = proba_to_class(model2.predict_proba(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67dc94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_rf_train = accuracy_score(y_train,y_pred_train_rf)\n",
    "acc_rf_val = accuracy_score(y_val,y_pred_val_rf)\n",
    "acc_rf_test = accuracy_score(y_test,y_pred_test_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec337a1b",
   "metadata": {},
   "source": [
    "### Perform a search on minimum depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240ce34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "randfor2 = RandomForestClassifier(random_state=42)\n",
    "max_depth = np.arange(start=2,stop=8)\n",
    "param_grid1 = {'max_depth':max_depth}\n",
    "cv = 10\n",
    "scoring = 'accuracy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238015f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = GridSearchCV(estimator=randfor2,param_grid=param_grid1,cv=cv,scoring=scoring,return_train_score=True,verbose=3)\n",
    "clf1.fit(X_train,y_train)\n",
    "clf1.best_estimator_\n",
    "clf1.score(X_train,y_train)\n",
    "clf1.score(X_val, y_val)\n",
    "clf1.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e11735b",
   "metadata": {},
   "source": [
    "### Perform a search on minimum samples per node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b94e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "randfor3 = RandomForestClassifier(random_state=42,max_depth=7)\n",
    "min_samples_split = np.linspace(start=2, stop=256, num=5).astype(int)\n",
    "param_grid2 = {'min_samples_split':min_samples_split}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3d2370",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf2 = GridSearchCV(estimator=randfor3,param_grid=param_grid2,cv=cv,scoring=scoring,return_train_score=True,verbose=3)\n",
    "clf2.fit(X_train,y_train)\n",
    "clf2.best_estimator_\n",
    "clf2.score(X_val, y_val)\n",
    "clf2.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff9fb99",
   "metadata": {},
   "source": [
    "### Perform a search on number of samples per node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b66b633",
   "metadata": {},
   "outputs": [],
   "source": [
    "randfor4 = RandomForestClassifier(random_state=42,max_depth=7,min_samples_split=65)\n",
    "n_estimators = np.linspace(start=2, stop=256, num=5).astype(int)\n",
    "param_grid3 = {'n_estimators':n_estimators}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70640012",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf3 = GridSearchCV(estimator=randfor4,param_grid=param_grid3,cv=cv,scoring=scoring,return_train_score=True,verbose=3)\n",
    "clf3.fit(X_train,y_train)\n",
    "clf3.best_estimator_\n",
    "clf3.score(X_val, y_val)\n",
    "clf3.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8b37e5",
   "metadata": {},
   "source": [
    "## PyTorch models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5622a3",
   "metadata": {},
   "source": [
    "### Useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246c46a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def proba_to_class(probs):\n",
    "    return np.argmax(probs, axis=1)\n",
    "\n",
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda:0')\n",
    "    else:\n",
    "        device = torch.device('cpu') # don't have GPU \n",
    "    return device\n",
    "\n",
    "class PytorchDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Pytorch dataset\n",
    "    ...\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    X_tensor : Pytorch tensor\n",
    "        Features tensor\n",
    "    y_tensor : Pytorch tensor\n",
    "        Target tensor\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    __getitem__(index)\n",
    "        Return features and target for a given index\n",
    "    __len__\n",
    "        Return the number of observations\n",
    "    to_tensor(data)\n",
    "        Convert Pandas Series to Pytorch tensor\n",
    "    \"\"\"\n",
    "        \n",
    "    def __init__(self, X, y):\n",
    "        self.X_tensor = self.to_tensor(X)\n",
    "        self.y_tensor = self.to_tensor(y)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_tensor[index], self.y_tensor[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_tensor)\n",
    "    \n",
    "    def to_tensor(self, data):\n",
    "        if type(data) == pd.core.frame.DataFrame:\n",
    "            data_out = data.values\n",
    "        if type(data) == np.ndarray:\n",
    "            data_out = data\n",
    "        return torch.Tensor(data_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66e7b93",
   "metadata": {},
   "source": [
    "### Neural network 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146267b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegressionModel(nn.Module):\n",
    "     def __init__(self, input_dim):\n",
    "        super(LogisticRegressionModel,self).__init__()\n",
    "        \n",
    "        self.layer1 = nn.Linear(input_dim, 128)\n",
    "        self.layerout = nn.Linear(128, 103)\n",
    "        \n",
    "     def forward(self, x):\n",
    "         x = F.relu(self.layer1(x))\n",
    "         x = F.sigmoid(self.layerout(x))\n",
    "         return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710459d8",
   "metadata": {},
   "source": [
    "### Neural network 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a696172",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegressionModel2(nn.Module):\n",
    "     def __init__(self, input_dim):\n",
    "        super(LogisticRegressionModel2,self).__init__()\n",
    "        \n",
    "        self.layer1 = nn.Linear(input_dim, 256)\n",
    "        self.layerout = nn.Linear(256, 103)\n",
    "        \n",
    "     def forward(self, x):\n",
    "         x = F.relu(self.layer1(x))\n",
    "         x = F.sigmoid(self.layerout(x))\n",
    "         return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99cf8e7e",
   "metadata": {},
   "source": [
    "### Neural network 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef81f691",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepNeuralNet1(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "      super(DeepNeuralNet1,self).__init__()\n",
    "      self.fc1 = nn.Linear(input_dim, 512)\n",
    "      self.fc2 = nn.Linear(512,512)\n",
    "      self.fc3 = nn.Linear(512,103)\n",
    "      self.droput = nn.Dropout(0.2)\n",
    "        \n",
    "    def forward(self,x):\n",
    "          x = F.relu(self.fc1(x))\n",
    "          x = self.droput(x)\n",
    "          x = F.relu(self.fc2(x))\n",
    "          x = self.droput(x)\n",
    "          x = self.fc3(x)\n",
    "          return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae505dbb",
   "metadata": {},
   "source": [
    "### Call NN ML class constructors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df683f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = LogisticRegressionModel(X_train.shape[1])   \n",
    "model2 = LogisticRegressionModel2(X_train.shape[1]) \n",
    "model3 = DeepNeuralNet1(X_train.shape[1]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0339ceaa",
   "metadata": {},
   "source": [
    "### Set useful constants and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1687db",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = get_device()\n",
    "\n",
    "train_dataset = PytorchDataset(X=X_train, y=y_train)\n",
    "val_dataset = PytorchDataset(X=X_val, y=y_val)\n",
    "test_dataset = PytorchDataset(X=X_test, y=y_test)\n",
    "\n",
    "batch_size_test = y_test.shape[0]\n",
    "\n",
    "num_epochs = 50\n",
    "batch_size = 100\n",
    "batch_size_test = y_test.shape[0]\n",
    "learning_rate = 0.01\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.SGD(lr =learning_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef551d6e",
   "metadata": {},
   "source": [
    "### Define function for NN training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba25390",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(model,num_epochs,batch_size):\n",
    "    for epoch in range(num_epochs): # monitoring the losses\n",
    "        train_data = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        val_data = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "        training_loss = 0\n",
    "        validation_loss = 0\n",
    "        size = 0\n",
    "        accuracy = 0\n",
    "        \n",
    "        model.train()\n",
    "        for batch_idx, (data,label) in enumerate(train_data):\n",
    "            optimizer.zero_grad() \n",
    "            output = model(data)\n",
    "            label = label.to(torch.long)\n",
    "            loss = criterion(output,label)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            training_loss += loss.item()\n",
    "            size += label.shape[0]\n",
    "            values, indices = output.max(1)\n",
    "            accuracy += (indices == label).sum()\n",
    "        \n",
    "        model.eval()\n",
    "        for batch_idx, (data,label) in enumerate(val_data):\n",
    "            output = model(data)\n",
    "            label = label.to(torch.long)\n",
    "            loss = criterion(output,label)\n",
    "            validation_loss += loss.item()\n",
    "    \n",
    "        training_loss /= size\n",
    "        validation_loss /= size\n",
    "        accuracy = accuracy.float()/size*100\n",
    "        print('Epoch: %5s, Train Loss: %6f, Validation Loss: %6f, Accuracy: %6f\\n' %(str(epoch), training_loss, validation_loss, accuracy))\n",
    "    return model     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9091ed0b",
   "metadata": {},
   "source": [
    "### Define function for NN prediction generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fad1db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_generation(model,batch_size):\n",
    "    model.eval()\n",
    "    testing_loss = 0.0\n",
    "    test_data = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "    for batch_idx, (data,label) in enumerate(test_data):\n",
    "        output = model(data) \n",
    "        label = label.to(torch.long)\n",
    "        loss = criterion(output,label)\n",
    "        testing_loss += loss.item()\n",
    "        _, predictions = torch.max(output, 1)\n",
    "        testing_loss /= len(test_dataset)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4876d7a6",
   "metadata": {},
   "source": [
    "### Train for three defined NN models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea58a37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = training_loop(model1,num_epochs=num_epochs,batch_size=batch_size)\n",
    "y_pred_nnlogreg1 = prediction_generation(model1,batch_size=batch_size_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a019039",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = training_loop(model2,num_epochs=num_epochs,batch_size=batch_size)\n",
    "y_pred_nnlogreg2 = prediction_generation(model2,batch_size=batch_size_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d60006",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = training_loop(model3,num_epochs=num_epochs,batch_size=batch_size)\n",
    "y_pred_nn3 = prediction_generation(model3,batch_size=batch_size_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa3b263",
   "metadata": {},
   "source": [
    "# Pipeline Definition for API Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1f7a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_var_transformer = Pipeline(\n",
    "    steps=[\n",
    "        ('brewery_name_encoder', MinMaxScaler())\n",
    "    ]\n",
    ")\n",
    "\n",
    "num_var_transformer = Pipeline(\n",
    "    steps=[\n",
    "        ('beer_measures_encoder', OrdinalEncoder())\n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('fac_cols', cat_var_transformer, factor_cols),\n",
    "        ('num_cols', num_var_transformer, numerical_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "model_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('log_regression', LogisticRegression(max_iter=10000)) ## This line is set to the final model used for API\n",
    "    ]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
