{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1083cea1",
   "metadata": {},
   "source": [
    "# Package Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a420a3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI\n",
    "from starlette.responses import JSONResponse\n",
    "from joblib import dump\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from category_encoders.ordinal import OrdinalEncoder\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639a96f5",
   "metadata": {},
   "source": [
    "# Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb74165",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_raw = pd.read_csv('../data/raw/beer_reviews.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75bfa9d5",
   "metadata": {},
   "source": [
    "# Dataset Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e6b9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_clean1 = df_data_raw.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376fe011",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define columns to be used for various steps later\n",
    "col_usable = ['brewery_name','review_aroma','review_appearance','review_palate','review_taste','beer_abv','beer_style']\n",
    "independent_cols = ['brewery_name','review_aroma','review_appearance','review_palate','review_taste','beer_abv']\n",
    "numerical_cols = ['review_aroma','review_appearance','review_palate','review_taste','beer_abv']\n",
    "factor_cols = ['brewery_name']\n",
    "target_col = ['beer_style']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710de90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select only the required columns\n",
    "df_data_reduced1 = df_data_clean1.loc[:,col_usable]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a2dc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take another copy for filtering out null values and split off the target variable column\n",
    "df_data_reduced2 = df_data_reduced1.copy()\n",
    "df_data_reduced2 = df_data_reduced2.dropna()\n",
    "target = df_data_reduced2.pop('beer_style')\n",
    "df_data_reduced2.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c61bbf",
   "metadata": {},
   "source": [
    "# Define transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922019ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Factor column\n",
    "factor_encoder = OrdinalEncoder()\n",
    "df_data_reduced2[factor_cols] = factor_encoder.fit_transform(df_data_reduced2[factor_cols])\n",
    "#Numerical columns - all set to standard default range of [0.0,1.0]\n",
    "numerical_encoder = MinMaxScaler()\n",
    "df_data_reduced2[numerical_cols] = numerical_encoder.fit_transform(df_data_reduced2[numerical_cols])\n",
    "#Target column\n",
    "target_encoder = LabelEncoder()\n",
    "target_out = target_encoder.fit_transform(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6749a4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the target column transformer for inverse transformation in app\n",
    "dump(target_encoder,'../models/target_decoder.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81359fda",
   "metadata": {},
   "source": [
    "# Dataset splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef63c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_data_reduced2, target_out, train_size=0.7, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, train_size=0.7, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da007617",
   "metadata": {},
   "source": [
    "# ML Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336f6d77",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ee0ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(max_iter=10000)\n",
    "model = logreg.fit(X_train,y_train)\n",
    "y_pred_train = proba_to_class(model.predict_proba(X_train))\n",
    "y_pred_val = proba_to_class(model.predict_proba(X_val))\n",
    "y_pred_test = proba_to_class(model.predict_proba(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a459a4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_logreg_train = accuracy_score(y_train,y_pred_train)\n",
    "acc_logreg_val = accuracy_score(y_val,y_pred_val)\n",
    "acc_logreg_test = accuracy_score(y_test,y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897b6686",
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(model,'../models/logreg_base.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4922fe48",
   "metadata": {},
   "source": [
    "## Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8415f44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layer_sizes=512\n",
    "nn_classifier_model = MLPClassifier(hidden_layer_sizes=hidden_layer_sizes, solver='sgd', learning_rate='adaptive', random_state=42)\n",
    "model3 = nn_classifier_model.fit(X_train,y_train)\n",
    "y_pred_train_nn01 = proba_to_class(model3.predict_proba(X_train))\n",
    "y_pred_val_nn01 = proba_to_class(model3.predict_proba(X_val))\n",
    "y_pred_test_nn01 = proba_to_class(model3.predict_proba(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285e26d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_nn01_train = accuracy_score(y_train,y_pred_train_nn01)\n",
    "acc_nn01_val = accuracy_score(y_val,y_pred_val_nn01)\n",
    "acc_nn01_test = accuracy_score(y_test,y_pred_test_nn01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cac121f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(model3,'../models/nn_sklearn_base.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6c33eb",
   "metadata": {},
   "source": [
    "## Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb62d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "randfor = RandomForestClassifier(random_state=42,max_depth=4)\n",
    "model2 = randfor.fit(X_train,y_train)\n",
    "y_pred_train_rf = proba_to_class(model2.predict_proba(X_train))\n",
    "y_pred_val_rf = proba_to_class(model2.predict_proba(X_val))\n",
    "y_pred_test_rf = proba_to_class(model2.predict_proba(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385ed06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_rf_train = accuracy_score(y_train,y_pred_train_rf)\n",
    "acc_rf_val = accuracy_score(y_val,y_pred_val_rf)\n",
    "acc_rf_test = accuracy_score(y_test,y_pred_test_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9c8e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(model2,'../models/randfor_base.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a37122",
   "metadata": {},
   "source": [
    "### Perform a search on minimum depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546b0dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "randfor2 = RandomForestClassifier(random_state=42)\n",
    "max_depth = np.arange(start=2,stop=8)\n",
    "param_grid1 = {'max_depth':max_depth}\n",
    "cv = 10\n",
    "scoring = 'accuracy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691ed94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = GridSearchCV(estimator=randfor2,param_grid=param_grid1,cv=cv,scoring=scoring,return_train_score=True,verbose=3)\n",
    "clf1.fit(X_train,y_train)\n",
    "clf1.best_estimator_\n",
    "clf1.score(X_train,y_train)\n",
    "clf1.score(X_val, y_val)\n",
    "clf1.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d56687",
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(clf1,'../models/randfor_grid1.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95bba08b",
   "metadata": {},
   "source": [
    "### Perform a search on minimum samples per node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52cd5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "randfor3 = RandomForestClassifier(random_state=42,max_depth=7)\n",
    "min_samples_split = np.linspace(start=2, stop=256, num=5).astype(int)\n",
    "param_grid2 = {'min_samples_split':min_samples_split}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb67f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf2 = GridSearchCV(estimator=randfor3,param_grid=param_grid2,cv=cv,scoring=scoring,return_train_score=True,verbose=3)\n",
    "clf2.fit(X_train,y_train)\n",
    "clf2.best_estimator_\n",
    "clf2.score(X_train,y_train)\n",
    "clf2.score(X_val, y_val)\n",
    "clf2.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7e77ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(clf2,'../models/randfor_grid2.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0b71d7",
   "metadata": {},
   "source": [
    "### Perform a search on number of samples per node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fb87b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "randfor4 = RandomForestClassifier(random_state=42,max_depth=7,min_samples_split=65)\n",
    "n_estimators = np.linspace(start=2, stop=256, num=5).astype(int)\n",
    "param_grid3 = {'n_estimators':n_estimators}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c72348",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf3 = GridSearchCV(estimator=randfor4,param_grid=param_grid3,cv=cv,scoring=scoring,return_train_score=True,verbose=3)\n",
    "clf3.fit(X_train,y_train)\n",
    "clf3.best_estimator_\n",
    "clf3.score(X_train,y_train)\n",
    "clf3.score(X_val, y_val)\n",
    "clf3.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4f57b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(clf3,'../models/randfor_grid3.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614387d0",
   "metadata": {},
   "source": [
    "## PyTorch models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f68753d",
   "metadata": {},
   "source": [
    "### Useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74cdb24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def proba_to_class(probs):\n",
    "    return np.argmax(probs, axis=1)\n",
    "\n",
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda:0')\n",
    "    else:\n",
    "        device = torch.device('cpu') # don't have GPU \n",
    "    return device\n",
    "\n",
    "class PytorchDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Pytorch dataset\n",
    "    ...\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    X_tensor : Pytorch tensor\n",
    "        Features tensor\n",
    "    y_tensor : Pytorch tensor\n",
    "        Target tensor\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    __getitem__(index)\n",
    "        Return features and target for a given index\n",
    "    __len__\n",
    "        Return the number of observations\n",
    "    to_tensor(data)\n",
    "        Convert Pandas Series to Pytorch tensor\n",
    "    \"\"\"\n",
    "        \n",
    "    def __init__(self, X, y):\n",
    "        self.X_tensor = self.to_tensor(X)\n",
    "        self.y_tensor = self.to_tensor(y)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_tensor[index], self.y_tensor[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_tensor)\n",
    "    \n",
    "    def to_tensor(self, data):\n",
    "        if type(data) == pd.core.frame.DataFrame:\n",
    "            data_out = data.values\n",
    "        if type(data) == np.ndarray:\n",
    "            data_out = data\n",
    "        return torch.Tensor(data_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "becb7cbe",
   "metadata": {},
   "source": [
    "### Neural network 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83cb11b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegressionModel(nn.Module):\n",
    "     def __init__(self, input_dim):\n",
    "        super(LogisticRegressionModel,self).__init__()\n",
    "        \n",
    "        self.layer1 = nn.Linear(input_dim, 128)\n",
    "        self.layerout = nn.Linear(128, 103)\n",
    "        \n",
    "     def forward(self, x):\n",
    "         x = F.relu(self.layer1(x))\n",
    "         x = F.sigmoid(self.layerout(x))\n",
    "         return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6a4211",
   "metadata": {},
   "source": [
    "### Neural network 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca0cf0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegressionModel2(nn.Module):\n",
    "     def __init__(self, input_dim):\n",
    "        super(LogisticRegressionModel2,self).__init__()\n",
    "        \n",
    "        self.layer1 = nn.Linear(input_dim, 256)\n",
    "        self.layerout = nn.Linear(256, 103)\n",
    "        \n",
    "     def forward(self, x):\n",
    "         x = F.relu(self.layer1(x))\n",
    "         x = F.sigmoid(self.layerout(x))\n",
    "         return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad95b08",
   "metadata": {},
   "source": [
    "### Neural network 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27fb2282",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepNeuralNet1(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "      super(DeepNeuralNet1,self).__init__()\n",
    "      self.fc1 = nn.Linear(input_dim, 512)\n",
    "      self.fc2 = nn.Linear(512,512)\n",
    "      self.fc3 = nn.Linear(512,103)\n",
    "      self.droput = nn.Dropout(0.2)\n",
    "        \n",
    "    def forward(self,x):\n",
    "          x = F.relu(self.fc1(x))\n",
    "          x = self.droput(x)\n",
    "          x = F.relu(self.fc2(x))\n",
    "          x = self.droput(x)\n",
    "          x = self.fc3(x)\n",
    "          return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6afa1097",
   "metadata": {},
   "source": [
    "### Call NN ML class constructors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0b79d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = LogisticRegressionModel(X_train.shape[1])   \n",
    "model2 = LogisticRegressionModel2(X_train.shape[1]) \n",
    "model3 = DeepNeuralNet1(X_train.shape[1]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3d8606",
   "metadata": {},
   "source": [
    "### Set useful constants and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c247a4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = get_device()\n",
    "\n",
    "train_dataset = PytorchDataset(X=X_train, y=y_train)\n",
    "val_dataset = PytorchDataset(X=X_val, y=y_val)\n",
    "test_dataset = PytorchDataset(X=X_test, y=y_test)\n",
    "\n",
    "batch_size_test = y_test.shape[0]\n",
    "\n",
    "num_epochs = 50\n",
    "batch_size = 100\n",
    "batch_size_test = y_test.shape[0]\n",
    "learning_rate = 0.01\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.SGD(lr =learning_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acfde0ac",
   "metadata": {},
   "source": [
    "### Define PyTorch datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633f79b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = DataLoader(train_dataset, batch_size=batch_size_train, shuffle=True)\n",
    "val_data = DataLoader(val_dataset, batch_size=batch_size_val, shuffle=True)\n",
    "test_data = DataLoader(test_dataset, batch_size=batch_size_test, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5039c0",
   "metadata": {},
   "source": [
    "### Define function for NN training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19cee098",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(model,num_epochs,batch_size):\n",
    "    for epoch in range(num_epochs): # monitoring the losses\n",
    "        train_data = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        val_data = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "        training_loss = 0\n",
    "        validation_loss = 0\n",
    "        size = 0\n",
    "        accuracy = 0\n",
    "        \n",
    "        model.train()\n",
    "        for batch_idx, (data,label) in enumerate(train_data):\n",
    "            optimizer.zero_grad() \n",
    "            output = model(data)\n",
    "            label = label.to(torch.long)\n",
    "            loss = criterion(output,label)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            training_loss += loss.item()\n",
    "            size += label.shape[0]\n",
    "            values, indices = output.max(1)\n",
    "            accuracy += (indices == label).sum()\n",
    "        \n",
    "        model.eval()\n",
    "        for batch_idx, (data,label) in enumerate(val_data):\n",
    "            output = model(data)\n",
    "            label = label.to(torch.long)\n",
    "            loss = criterion(output,label)\n",
    "            validation_loss += loss.item()\n",
    "    \n",
    "        training_loss /= size\n",
    "        validation_loss /= size\n",
    "        accuracy = accuracy.float()/size*100\n",
    "        print('Epoch: %5s, Train Loss: %6f, Validation Loss: %6f, Accuracy: %6f\\n' %(str(epoch), training_loss, validation_loss, accuracy))\n",
    "    return model     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4cce42",
   "metadata": {},
   "source": [
    "### Define function for NN prediction generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdba313",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_generation(model,test_data,batch_size):\n",
    "    model.eval()\n",
    "    testing_loss = 0.0\n",
    "    \n",
    "    for batch_idx, (data,label) in enumerate(test_data):\n",
    "        output = model(data) \n",
    "        label = label.to(torch.long)\n",
    "        loss = criterion(output,label)\n",
    "        testing_loss += loss.item()\n",
    "        _, predictions = torch.max(output, 1)\n",
    "        testing_loss /= len(test_dataset)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd47ee78",
   "metadata": {},
   "source": [
    "### Train for three defined NN models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9770d681",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = training_loop(model1,num_epochs=num_epochs,batch_size=batch_size)\n",
    "y_pred_nnlogreg1_train = prediction_generation(model1,train_data,batch_size=batch_size_train)\n",
    "y_pred_nnlogreg1_val = prediction_generation(model1,val_data,batch_size=batch_size_val)\n",
    "y_pred_nnlogreg1_test = prediction_generation(model1,test_data,batch_size=batch_size_test)\n",
    "\n",
    "acc_nnlogreg1_train = accuracy_score(y_train,y_pred_nnlogreg1_train.numpy())\n",
    "acc_nnlogreg1_val = accuracy_score(y_val,y_pred_nnlogreg1_val.numpy())\n",
    "acc_nnlogreg1_test = accuracy_score(y_test,y_pred_nnlogreg1_test.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80025c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model1, '../models/NN01.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d17f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = training_loop(model2,num_epochs=num_epochs,batch_size=batch_size)\n",
    "y_pred_nnlogreg2_train = prediction_generation(model2,train_data,batch_size=batch_size_train)\n",
    "y_pred_nnlogreg2_val = prediction_generation(model2,val_data,batch_size=batch_size_val)\n",
    "y_pred_nnlogreg2_test = prediction_generation(model2,test_data,batch_size=batch_size_test)\n",
    "\n",
    "acc_nnlogreg2_train = accuracy_score(y_train,y_pred_nnlogreg2_train.numpy())\n",
    "acc_nnlogreg2_val = accuracy_score(y_val,y_pred_nnlogreg2_val.numpy())\n",
    "acc_nnlogreg2_test = accuracy_score(y_test,y_pred_nnlogreg2_test.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a06425",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model1, '../models/NN02.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2c3729",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = training_loop(model3,num_epochs=num_epochs,batch_size=batch_size)\n",
    "y_pred_nn3_train = prediction_generation(model3,train_data,batch_size=batch_size_train)\n",
    "y_pred_nn3_val = prediction_generation(model3,val_data,batch_size=batch_size_val)\n",
    "y_pred_nn3_test = prediction_generation(model3,test_data,batch_size=batch_size_test)\n",
    "\n",
    "acc_nn3_train = accuracy_score(y_train,y_pred_nn3_train.numpy())\n",
    "acc_nn3_val = accuracy_score(y_val,y_pred_nn3_val.numpy())\n",
    "acc_nn3_test = accuracy_score(y_test,y_pred_nn3_test.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7552c18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model1, '../models/NN03.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5543ee",
   "metadata": {},
   "source": [
    "# Pipeline Definition for API Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91cef3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_var_transformer = Pipeline(\n",
    "    steps=[\n",
    "        ('brewery_name_encoder', MinMaxScaler())\n",
    "    ]\n",
    ")\n",
    "\n",
    "num_var_transformer = Pipeline(\n",
    "    steps=[\n",
    "        ('beer_measures_encoder', OrdinalEncoder())\n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('fac_cols', cat_var_transformer, factor_cols),\n",
    "        ('num_cols', num_var_transformer, numerical_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "model_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('log_regression', LogisticRegression(max_iter=10000)) ## This line is set to the final model used for API\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d260a4b7",
   "metadata": {},
   "source": [
    "## Fit and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e62cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use the original sub-dataset for training\n",
    "df_data_reduced1=df_data_reduced1.dropna()\n",
    "df_data_reduced1.pop('beer_style')\n",
    "X1, X2, y1, y2 = train_test_split(df_data_reduced1, target_out, train_size=0.7, random_state=42)\n",
    "model_pipeline.fit(X1,y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27cf68ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(model_pipeline,'../models/pipeline.joblib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
